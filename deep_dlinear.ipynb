{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/pytorch_forecasting/models/base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.data_utils import split_dataset, TimeSeriesDataset\n",
    "from utils.evaluation_utils import plot_multistep_forecast\n",
    "from utils.training_utils import train\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETTm2 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTm2.csv\")\n",
    "training_df, test_df = split_dataset(ETTm2, remain_same = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lag = 96\n",
    "future_steps = 48\n",
    "batch_size = 8\n",
    "epochs = 8\n",
    "learning_rate=1.e-4\n",
    "decomp_kernel_size = 24\n",
    "number_of_forecasts = 100\n",
    "target_column = ['OT']\n",
    "feature_columns = [i for i in training_df.columns]\n",
    "modelling_task = 'univariate'\n",
    "n_continous_features=7\n",
    "n_categorial_features=5\n",
    "dataset_name = 'ETTm2DeepTraining'\n",
    "depth = 'deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n",
      "Univatiate modelling\n",
      "inflation factor = 1\n",
      "Dlinear activated\n",
      "Points to be estimated\n",
      "With a deep network\n",
      "Current learning rate is : 0.0001\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 8.904723795318603\n",
      "Current (running) training loss at iteration 10000 : 7.500785620880127\n",
      "Current (running) training loss at iteration 15000 : 5.8730678658564885\n",
      "Current (running) training loss at iteration 20000 : 4.751152615499496\n",
      "Current (running) training loss at iteration 25000 : 4.178857899552583\n",
      "Current (running) training loss at iteration 30000 : 4.124328269802531\n",
      "Current (running) training loss at iteration 35000 : 4.026164241401638\n",
      "Current (running) training loss at iteration 40000 : 3.794937326558679\n",
      "Current (running) training loss at iteration 45000 : 3.618112332343393\n",
      "\n",
      "Epoch 0: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 3.545234513247935.\n",
      "Training MAE is 0.4567457047706191.\n",
      "Training MSE is 3.5947368535225617.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 13.145428428912691.\n",
      "Test MAE is 1.0325043435030887.\n",
      "Test MSE is 13.205633939979867.\n",
      "---------------------------\n",
      "Current learning rate is : 5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 3.087259283053875\n",
      "Current (running) training loss at iteration 10000 : 3.257444758552313\n",
      "Current (running) training loss at iteration 15000 : 2.8045795374274256\n",
      "Current (running) training loss at iteration 20000 : 2.4481293556645514\n",
      "Current (running) training loss at iteration 25000 : 2.349321489869356\n",
      "Current (running) training loss at iteration 30000 : 2.5472898843536775\n",
      "Current (running) training loss at iteration 35000 : 2.692689608033214\n",
      "Current (running) training loss at iteration 40000 : 2.690543217844516\n",
      "Current (running) training loss at iteration 45000 : 2.69159419919716\n",
      "\n",
      "Epoch 1: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 2.6505167106273047.\n",
      "Training MAE is 0.43402034093719327.\n",
      "Training MSE is 2.706366585530583.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 12.615362473623925.\n",
      "Test MAE is 1.0359731408217523.\n",
      "Test MSE is 12.680509969801822.\n",
      "---------------------------\n",
      "Current learning rate is : 5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.5364105187654493\n",
      "Current (running) training loss at iteration 10000 : 2.7644110890388487\n",
      "Current (running) training loss at iteration 15000 : 2.492487001937628\n",
      "Current (running) training loss at iteration 20000 : 2.218079055787623\n",
      "Current (running) training loss at iteration 25000 : 2.175761432772875\n",
      "Current (running) training loss at iteration 30000 : 2.3777854651431243\n",
      "Current (running) training loss at iteration 35000 : 2.4572398648142815\n",
      "Current (running) training loss at iteration 40000 : 2.462178086298704\n",
      "Current (running) training loss at iteration 45000 : 2.4552446291923524\n",
      "\n",
      "Epoch 2: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 2.4145030002861083.\n",
      "Training MAE is 0.41864022294920206.\n",
      "Training MSE is 2.470140259426423.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 11.76477996002487.\n",
      "Test MAE is 1.0090749489640283.\n",
      "Test MSE is 11.834590391939496.\n",
      "---------------------------\n",
      "Current learning rate is : 2.5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.2157969139814377\n",
      "Current (running) training loss at iteration 10000 : 2.3615567176103593\n",
      "Current (running) training loss at iteration 15000 : 2.250711059141159\n",
      "Current (running) training loss at iteration 20000 : 2.0345660497516396\n",
      "Current (running) training loss at iteration 25000 : 2.017057664501667\n",
      "Current (running) training loss at iteration 30000 : 2.3079867606401443\n",
      "Current (running) training loss at iteration 35000 : 2.355821475485393\n",
      "Current (running) training loss at iteration 40000 : 2.3336815221741793\n",
      "Current (running) training loss at iteration 45000 : 2.321111816631423\n",
      "\n",
      "Epoch 3: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 2.284516284695969.\n",
      "Training MAE is 0.40779804984447726.\n",
      "Training MSE is 2.343214087556434.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 11.63856273712846.\n",
      "Test MAE is 1.0063861209340788.\n",
      "Test MSE is 11.711047130076505.\n",
      "---------------------------\n",
      "Current learning rate is : 2.5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 1.7188024313092232\n",
      "Current (running) training loss at iteration 10000 : 1.9326902198910714\n",
      "Current (running) training loss at iteration 15000 : 1.841745663269361\n",
      "Current (running) training loss at iteration 20000 : 1.6757914176136255\n",
      "Current (running) training loss at iteration 25000 : 1.721387763888836\n",
      "Current (running) training loss at iteration 30000 : 1.9938102596700191\n",
      "Current (running) training loss at iteration 35000 : 2.0575799278174127\n",
      "Current (running) training loss at iteration 40000 : 2.0469188628003003\n",
      "Current (running) training loss at iteration 45000 : 2.0537894856201278\n",
      "\n",
      "Epoch 4: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 2.0213198309956337.\n",
      "Training MAE is 0.3841347010036003.\n",
      "Training MSE is 2.081357241673609.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 10.893521858254719.\n",
      "Test MAE is 0.9697314502224379.\n",
      "Test MSE is 10.969055140484059.\n",
      "---------------------------\n",
      "Current learning rate is : 1.25e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.0802951523542403\n",
      "Current (running) training loss at iteration 10000 : 1.9830068437099457\n",
      "Current (running) training loss at iteration 15000 : 1.910140139957269\n",
      "Current (running) training loss at iteration 20000 : 1.7039297887265683\n",
      "Current (running) training loss at iteration 25000 : 1.718645172214508\n",
      "Current (running) training loss at iteration 30000 : 1.9416669519821803\n",
      "Current (running) training loss at iteration 35000 : 1.959884906087603\n",
      "Current (running) training loss at iteration 40000 : 1.9281418287381529\n",
      "Current (running) training loss at iteration 45000 : 1.9326925069305632\n",
      "\n",
      "Epoch 5: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.9064755879518676.\n",
      "Training MAE is 0.37214236795192673.\n",
      "Training MSE is 1.969025370441875.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 10.928398256037413.\n",
      "Test MAE is 0.9678389855583817.\n",
      "Test MSE is 11.011692282030022.\n",
      "---------------------------\n",
      "Current learning rate is : 1.25e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 1.5101978493452073\n",
      "Current (running) training loss at iteration 10000 : 1.6083468000292778\n",
      "Current (running) training loss at iteration 15000 : 1.5994837810238203\n",
      "Current (running) training loss at iteration 20000 : 1.448298705343902\n",
      "Current (running) training loss at iteration 25000 : 1.4985808800566196\n",
      "Current (running) training loss at iteration 30000 : 1.710013541445136\n",
      "Current (running) training loss at iteration 35000 : 1.7582224134113107\n",
      "Current (running) training loss at iteration 40000 : 1.7408895659171044\n",
      "Current (running) training loss at iteration 45000 : 1.7625517243219746\n",
      "\n",
      "Epoch 6: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.7408065255629246.\n",
      "Training MAE is 0.35614637751674644.\n",
      "Training MSE is 1.80444846028649.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 10.69202201832335.\n",
      "Test MAE is 0.9522726996254535.\n",
      "Test MSE is 10.776793685096154.\n",
      "---------------------------\n",
      "Current learning rate is : 6.25e-06\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.0305758437871932\n",
      "Current (running) training loss at iteration 10000 : 1.8470620101630688\n",
      "Current (running) training loss at iteration 15000 : 1.7979899650335311\n",
      "Current (running) training loss at iteration 20000 : 1.593592713534832\n",
      "Current (running) training loss at iteration 25000 : 1.600297192530632\n",
      "Current (running) training loss at iteration 30000 : 1.749557603931427\n",
      "Current (running) training loss at iteration 35000 : 1.7813120119231087\n",
      "Current (running) training loss at iteration 40000 : 1.7511353007972241\n",
      "Current (running) training loss at iteration 45000 : 1.7606361351264848\n",
      "\n",
      "Epoch 7: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.7394852405232124.\n",
      "Training MAE is 0.35639410085897.\n",
      "Training MSE is 1.8057045936022935.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 9.691406777056484.\n",
      "Test MAE is 0.9138372948866424.\n",
      "Test MSE is 9.778212921194507.\n",
      "---------------------------\n",
      "Current learning rate is : 6.25e-06\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 1.5924380309343338\n",
      "Current (running) training loss at iteration 10000 : 1.5841750972628594\n",
      "Current (running) training loss at iteration 15000 : 1.5687491025686264\n",
      "Current (running) training loss at iteration 20000 : 1.4054863889336586\n",
      "Current (running) training loss at iteration 25000 : 1.4368216754174232\n",
      "Current (running) training loss at iteration 30000 : 1.593020416055123\n",
      "Current (running) training loss at iteration 35000 : 1.6461773761051042\n",
      "Current (running) training loss at iteration 40000 : 1.6323737069830297\n",
      "Current (running) training loss at iteration 45000 : 1.6524068894757165\n",
      "\n",
      "Epoch 8: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.6341607168115198.\n",
      "Training MAE is 0.34549328327209583.\n",
      "Training MSE is 1.7007117471254087.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 9.425457031247818.\n",
      "Test MAE is 0.8967341127045804.\n",
      "Test MSE is 9.514602310163802.\n",
      "---------------------------\n",
      "Current learning rate is : 3.125e-06\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.399137222290039\n",
      "Current (running) training loss at iteration 10000 : 2.0139613268435\n",
      "Current (running) training loss at iteration 15000 : 1.8886263088186581\n",
      "Current (running) training loss at iteration 20000 : 1.6523507570236922\n",
      "Current (running) training loss at iteration 25000 : 1.627398566186428\n",
      "Current (running) training loss at iteration 30000 : 1.7470941056787967\n",
      "Current (running) training loss at iteration 35000 : 1.7859276453409876\n",
      "Current (running) training loss at iteration 40000 : 1.7435724268645048\n",
      "Current (running) training loss at iteration 45000 : 1.7438048792587386\n",
      "\n",
      "Epoch 9: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.723147889777237.\n",
      "Training MAE is 0.35472563836939247.\n",
      "Training MSE is 1.7892530051676754.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 8.366596073693453.\n",
      "Test MAE is 0.8498316162398883.\n",
      "Test MSE is 8.455008952918394.\n",
      "---------------------------\n",
      "Current learning rate is : 3.125e-06\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 1.7803773346543312\n",
      "Current (running) training loss at iteration 10000 : 1.6749029920756817\n",
      "Current (running) training loss at iteration 15000 : 1.6056299665808678\n",
      "Current (running) training loss at iteration 20000 : 1.4301445553421974\n",
      "Current (running) training loss at iteration 25000 : 1.4448545374643802\n",
      "Current (running) training loss at iteration 30000 : 1.5818842792123555\n",
      "Current (running) training loss at iteration 35000 : 1.6382714983420712\n",
      "Current (running) training loss at iteration 40000 : 1.61106074533239\n",
      "Current (running) training loss at iteration 45000 : 1.6245169469204215\n",
      "\n",
      "Epoch 10: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.6066618680937388.\n",
      "Training MAE is 0.3422891296977231.\n",
      "Training MSE is 1.6727178324015224.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 7.931259107445009.\n",
      "Test MAE is 0.8237354913536383.\n",
      "Test MSE is 8.019538930693955.\n",
      "---------------------------\n",
      "Current learning rate is : 1.5625e-06\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 3.210647034907341\n",
      "Current (running) training loss at iteration 10000 : 2.422820350676775\n",
      "Current (running) training loss at iteration 15000 : 2.147568923020363\n",
      "Current (running) training loss at iteration 20000 : 1.8537212969779968\n",
      "Current (running) training loss at iteration 25000 : 1.784570734026432\n",
      "Current (running) training loss at iteration 30000 : 1.8883563078502814\n",
      "Current (running) training loss at iteration 35000 : 1.9261373142123221\n",
      "Current (running) training loss at iteration 40000 : 1.8632065994128584\n",
      "Current (running) training loss at iteration 45000 : 1.8517320716142653\n",
      "\n",
      "Epoch 11: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.830064287815663.\n",
      "Training MAE is 0.3657197087209349.\n",
      "Training MSE is 1.897320058980383.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 7.264329935844141.\n",
      "Test MAE is 0.7924629045751295.\n",
      "Test MSE is 7.349150323567887.\n",
      "---------------------------\n",
      "Current learning rate is : 1.5625e-06\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 1.947767368030548\n",
      "Current (running) training loss at iteration 10000 : 1.7696839778721332\n",
      "Current (running) training loss at iteration 15000 : 1.6508312651753425\n",
      "Current (running) training loss at iteration 20000 : 1.467407385468483\n",
      "Current (running) training loss at iteration 25000 : 1.470109126057625\n",
      "Current (running) training loss at iteration 30000 : 1.6160838207602501\n",
      "Current (running) training loss at iteration 35000 : 1.6889676365733146\n",
      "Current (running) training loss at iteration 40000 : 1.6512737767338752\n",
      "Current (running) training loss at iteration 45000 : 1.6622721824407578\n",
      "\n",
      "Epoch 12: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.6451552789281823.\n",
      "Training MAE is 0.34693717663012047.\n",
      "Training MSE is 1.7120539493675038.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 6.8056506187898185.\n",
      "Test MAE is 0.7620838732523536.\n",
      "Test MSE is 6.889903732420146.\n",
      "---------------------------\n",
      "Current learning rate is : 7.8125e-07\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 3.690765789580345\n",
      "Current (running) training loss at iteration 10000 : 2.6823087508022785\n",
      "Current (running) training loss at iteration 15000 : 2.3188379657586418\n",
      "Current (running) training loss at iteration 20000 : 2.009772672098875\n",
      "Current (running) training loss at iteration 25000 : 1.906048214800358\n",
      "Current (running) training loss at iteration 30000 : 2.0164297789871695\n",
      "Current (running) training loss at iteration 35000 : 2.073621976898398\n",
      "Current (running) training loss at iteration 40000 : 1.997191094945371\n",
      "Current (running) training loss at iteration 45000 : 1.9830747790382968\n",
      "\n",
      "Epoch 13: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.9633289711385884.\n",
      "Training MAE is 0.3810615637424201.\n",
      "Training MSE is 2.0307935535889876.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 6.383296449442593.\n",
      "Test MAE is 0.7407371402730579.\n",
      "Test MSE is 6.466083950728157.\n",
      "---------------------------\n",
      "Current learning rate is : 7.8125e-07\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.048353731107712\n",
      "Current (running) training loss at iteration 10000 : 1.8399528385162354\n",
      "Current (running) training loss at iteration 15000 : 1.6962883274356524\n",
      "Current (running) training loss at iteration 20000 : 1.5244123116761445\n",
      "Current (running) training loss at iteration 25000 : 1.5174942433619498\n",
      "Current (running) training loss at iteration 30000 : 1.693251868679126\n",
      "Current (running) training loss at iteration 35000 : 1.7825809395602772\n",
      "Current (running) training loss at iteration 40000 : 1.7398929907470941\n",
      "Current (running) training loss at iteration 45000 : 1.7515105655815866\n",
      "\n",
      "Epoch 14: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 1.7365292553235077.\n",
      "Training MAE is 0.35761914961231456.\n",
      "Training MSE is 1.8033603599238228.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 6.082224460312131.\n",
      "Test MAE is 0.7180140606015606.\n",
      "Test MSE is 6.164965239525848.\n",
      "---------------------------\n",
      "Current learning rate is : 3.90625e-07\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_continous_features=n_continous_features, \n",
    "            n_categorial_features=n_categorial_features,\n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = test_df, \n",
    "            feature_columns = feature_columns,\n",
    "            target_column = target_column, \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size, \n",
    "            model = 'dlinear', \n",
    "            modelling_task = modelling_task, \n",
    "            dataset_name = dataset_name, \n",
    "            depth = depth\n",
    "            )\n",
    "test_data = DataLoader(TimeSeriesDataset(test_df, future_steps= future_steps, target_column = target_column,feature_columns=feature_columns,p_lag=p_lag), batch_size=batch_size,drop_last=True)\n",
    "plot_multistep_forecast(test_data=test_data, dataset_name = dataset_name, neural_net=net, future_steps=future_steps, number_of_forecasts=number_of_forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ue = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peter = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gustav = ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
