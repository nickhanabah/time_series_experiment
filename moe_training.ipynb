{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import split_dataset, TimeSeriesDataset\n",
    "from utils.evaluation_utils import plot_multistep_forecast\n",
    "from utils.training_utils import train\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETTm2 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTm2.csv\")\n",
    "training_df, test_df = split_dataset(ETTm2, remain_same = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lag = 48\n",
    "future_steps = 24\n",
    "batch_size = 8\n",
    "epochs = 1\n",
    "learning_rate=1.e-4\n",
    "decomp_kernel_size = 24\n",
    "number_of_forecasts = 100\n",
    "target_column = ['OT']\n",
    "feature_columns = [i for i in training_df.columns]\n",
    "modelling_task = 'univariate'\n",
    "n_continous_features=7\n",
    "n_categorial_features=5\n",
    "dataset_name = 'ETTm2LongTraining'\n",
    "moe = True\n",
    "number_of_experts = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Univatiate modelling\n",
      "inflation factor = 1\n",
      "Rlinear activated\n",
      "Points to be estimated\n",
      "Univatiate modelling\n",
      "inflation factor = 1\n",
      "Rlinear activated\n",
      "Points to be estimated\n",
      "Started training expert 1/2\n",
      "Current learning rate is : 0.0001\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 95.96770806274414\n",
      "Current (running) training loss at iteration 10000 : 102.68652168159485\n",
      "Current (running) training loss at iteration 15000 : 91.49046829427083\n",
      "Current (running) training loss at iteration 20000 : 88.55242709598541\n",
      "Current (running) training loss at iteration 25000 : 95.4094947454834\n",
      "Current (running) training loss at iteration 30000 : 101.82081117019654\n",
      "Current (running) training loss at iteration 35000 : 105.5169522038051\n",
      "Current (running) training loss at iteration 40000 : 104.91349835281372\n",
      "Current (running) training loss at iteration 45000 : 102.49887698135376\n",
      "\n",
      "Epoch 0: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 103.9930073846726.\n",
      "Training MAE is 2.6167259216308594.\n",
      "Training MSE is 103.97628021240234.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 94.73859827701862.\n",
      "Test MAE is 2.4985945224761963.\n",
      "Test MSE is 94.70079803466797.\n",
      "---------------------------\n",
      "Started training expert 2/2\n",
      "Current learning rate is : 0.0001\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 17.788511126327514\n",
      "Current (running) training loss at iteration 10000 : 15.255156373929978\n",
      "Current (running) training loss at iteration 15000 : 12.32489276971817\n",
      "Current (running) training loss at iteration 20000 : 10.447700547075272\n",
      "Current (running) training loss at iteration 25000 : 9.281679116601945\n",
      "Current (running) training loss at iteration 30000 : 8.384234762295087\n",
      "Current (running) training loss at iteration 35000 : 7.63900558199031\n",
      "Current (running) training loss at iteration 40000 : 6.921516748744249\n",
      "Current (running) training loss at iteration 45000 : 6.330018998295731\n",
      "\n",
      "Epoch 0: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 6.153002196510357.\n",
      "Training MAE is 0.6104947328567505.\n",
      "Training MSE is 6.214951515197754.\n",
      "\n",
      "Test metrics: -------\n",
      "Running (test) loss is 2.271507398979543.\n",
      "Test MAE is 0.3999852240085602.\n",
      "Test MSE is 2.342986583709717.\n",
      "---------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MoE.__init__() missing 1 required positional argument: 'input_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_continous_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_continous_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_categorial_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_categorial_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp_lag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43mp_lag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_df\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecomp_kernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecomp_kernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodelling_task\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodelling_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmoe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmoe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_of_experts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnumber_of_experts\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m test_data \u001b[38;5;241m=\u001b[39m DataLoader(TimeSeriesDataset(test_df, future_steps\u001b[38;5;241m=\u001b[39m future_steps, target_column \u001b[38;5;241m=\u001b[39m target_column,feature_columns\u001b[38;5;241m=\u001b[39mfeature_columns,p_lag\u001b[38;5;241m=\u001b[39mp_lag), batch_size\u001b[38;5;241m=\u001b[39mbatch_size,drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m plot_multistep_forecast(test_data\u001b[38;5;241m=\u001b[39mtest_data, dataset_name \u001b[38;5;241m=\u001b[39m dataset_name, neural_net\u001b[38;5;241m=\u001b[39mnet, future_steps\u001b[38;5;241m=\u001b[39mfuture_steps, number_of_forecasts\u001b[38;5;241m=\u001b[39mnumber_of_forecasts)\n",
      "File \u001b[0;32m/workspaces/time_series_experiment/utils/training_utils.py:202\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, p_lag, future_steps, n_continous_features, n_categorial_features, training_df, validation_df, feature_columns, dataset_name, target_column, learning_rate, decomp_kernel_size, batch_size, model, moe, num_of_experts, modelling_task, density, depth)\u001b[0m\n\u001b[1;32m    200\u001b[0m     trained_experts\u001b[38;5;241m.\u001b[39mappend(net)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m moe: \n\u001b[0;32m--> 202\u001b[0m     moe_model \u001b[38;5;241m=\u001b[39m \u001b[43mMoE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_experts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     optimizer_moe \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(moe_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "\u001b[0;31mTypeError\u001b[0m: MoE.__init__() missing 1 required positional argument: 'input_dim'"
     ]
    }
   ],
   "source": [
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_continous_features=n_continous_features, \n",
    "            n_categorial_features=n_categorial_features,\n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = test_df, \n",
    "            feature_columns = feature_columns,\n",
    "            target_column = target_column, \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size, \n",
    "            model = 'rlinear', \n",
    "            modelling_task = modelling_task, \n",
    "            dataset_name = dataset_name, \n",
    "            moe = moe, \n",
    "            num_of_experts = number_of_experts\n",
    "            )\n",
    "test_data = DataLoader(TimeSeriesDataset(test_df, future_steps= future_steps, target_column = target_column,feature_columns=feature_columns,p_lag=p_lag), batch_size=batch_size,drop_last=True)\n",
    "plot_multistep_forecast(test_data=test_data, dataset_name = dataset_name, neural_net=net, future_steps=future_steps, number_of_forecasts=number_of_forecasts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
