{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import split_dataset, TimeSeriesDataset\n",
    "from utils.evaluation_utils import plot_multistep_forecast, evaluate_on_test_data\n",
    "from utils.training_utils import train\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ETTm2 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTm2.csv\")\n",
    "ETTm1 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTm1.csv\")\n",
    "ETTh1 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTh1.csv\")\n",
    "ETTh2 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTh2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_lag = 96\n",
    "future_steps = 96\n",
    "batch_size = 8\n",
    "epochs = 16\n",
    "learning_rate=1.e-4\n",
    "decomp_kernel_size = 24\n",
    "one_layer = True\n",
    "number_of_forecasts = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETTm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/time_series_experiment/utils/data_utils.py:22: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  val_df = transform_date_column_and_drop_it(data[data['date'] > data['date'].min() + pd.DateOffset(months=train_split_month)][data['date'] < data['date'].min() + pd.DateOffset(months=val_split_month)],'date')\n",
      "/workspaces/time_series_experiment/utils/data_utils.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test_df = transform_date_column_and_drop_it(data[data['date'] > data['date'].min() + pd.DateOffset(months=val_split_month)][data['date'] < data['date'].min() + pd.DateOffset(months=test_split_month)],'date')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate is : 0.0001\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 5.622650940799713\n",
      "Current (running) training loss at iteration 10000 : 4.674999601507187\n",
      "Current (running) training loss at iteration 15000 : 3.8796694882949194\n",
      "Current (running) training loss at iteration 20000 : 3.497895229923725\n",
      "Current (running) training loss at iteration 25000 : 3.282611427612305\n",
      "Current (running) training loss at iteration 30000 : 3.9443907659431297\n",
      "\n",
      "Epoch 0: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 4.095129000666125.\n",
      "Training MAE is 0.5097232054511925.\n",
      "Training MSE is 4.129687593351875.\n",
      "Training MAPE is 58032469.23860914.\n",
      "\n",
      "Val metrics: -------\n",
      "Running (validation) loss is 7.663534840095216.\n",
      "Validation MAE is 0.25604410478084105.\n",
      "Validation MSE is 2.5692289759250166.\n",
      "Validation MAPE is 0.008618593327654056.\n",
      "---------------------------\n",
      "Current learning rate is : 5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 3.041510551428795\n",
      "Current (running) training loss at iteration 10000 : 3.426028072834015\n",
      "Current (running) training loss at iteration 15000 : 3.297850715025266\n",
      "Current (running) training loss at iteration 20000 : 2.925497789591551\n",
      "Current (running) training loss at iteration 25000 : 2.738280847043991\n",
      "Current (running) training loss at iteration 30000 : 4.085070231455565\n",
      "\n",
      "Epoch 1: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 4.242596124761539.\n",
      "Training MAE is 0.5009406362963829.\n",
      "Training MSE is 4.293654868735002.\n",
      "Training MAPE is 69778961.41901708.\n",
      "\n",
      "Val metrics: -------\n",
      "Running (validation) loss is 8.522136212093596.\n",
      "Validation MAE is 0.27753198824145575.\n",
      "Validation MSE is 2.8562458858023936.\n",
      "Validation MAPE is 0.009215626449031709.\n",
      "---------------------------\n",
      "Current learning rate is : 5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.63885306224823\n",
      "Current (running) training loss at iteration 10000 : 3.058969302970171\n",
      "Current (running) training loss at iteration 15000 : 2.9114680853764217\n",
      "Current (running) training loss at iteration 20000 : 2.598535790979862\n",
      "Current (running) training loss at iteration 25000 : 2.4407132620334626\n",
      "Current (running) training loss at iteration 30000 : 3.980041798665126\n",
      "\n",
      "Epoch 2: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 4.112061641650246.\n",
      "Training MAE is 0.4852975476379237.\n",
      "Training MSE is 4.166744116579137.\n",
      "Training MAPE is 70401382.04619776.\n",
      "\n",
      "Val metrics: -------\n",
      "Running (validation) loss is 9.260553864303906.\n",
      "Validation MAE is 0.2887815183269748.\n",
      "Validation MSE is 3.10301853227536.\n",
      "Validation MAPE is 0.009650834528938846.\n",
      "---------------------------\n",
      "Current learning rate is : 2.5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.7186752230644227\n",
      "Current (running) training loss at iteration 10000 : 2.793581472682953\n",
      "Current (running) training loss at iteration 15000 : 3.1023040497024854\n",
      "Current (running) training loss at iteration 20000 : 2.7139283430993557\n",
      "Current (running) training loss at iteration 25000 : 2.5695606935691835\n",
      "Current (running) training loss at iteration 30000 : 3.872769485751788\n",
      "\n",
      "Epoch 3: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 3.89264973274734.\n",
      "Training MAE is 0.479497938333943.\n",
      "Training MSE is 3.94944755851032.\n",
      "Training MAPE is 82304650.24832514.\n",
      "\n",
      "Val metrics: -------\n",
      "Running (validation) loss is 7.2946959186902465.\n",
      "Validation MAE is 0.25382335432031156.\n",
      "Validation MSE is 2.448562556728926.\n",
      "Validation MAPE is 0.00854456771372093.\n",
      "---------------------------\n",
      "Current learning rate is : 2.5e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.324014473426342\n",
      "Current (running) training loss at iteration 10000 : 2.4721212480962276\n",
      "Current (running) training loss at iteration 15000 : 2.563509351205826\n",
      "Current (running) training loss at iteration 20000 : 2.268102529302239\n",
      "Current (running) training loss at iteration 25000 : 2.1720680455327033\n",
      "Current (running) training loss at iteration 30000 : 3.1998148607730865\n",
      "\n",
      "Epoch 4: \n",
      "\n",
      "Train metrics: -------\n",
      "Running (training) loss is 3.246992101193268.\n",
      "Training MAE is 0.44405799205487645.\n",
      "Training MSE is 3.3050185033215143.\n",
      "Training MAPE is 79814043.17198327.\n",
      "\n",
      "Val metrics: -------\n",
      "Running (validation) loss is 6.430733930409406.\n",
      "Validation MAE is 0.23706916764488015.\n",
      "Validation MSE is 2.1610875615663656.\n",
      "Validation MAPE is 0.007983212441242752.\n",
      "---------------------------\n",
      "Current learning rate is : 1.25e-05\n",
      "---------------------------\n",
      "Current (running) training loss at iteration 5000 : 2.14895107884407\n",
      "Current (running) training loss at iteration 10000 : 2.273651753437519\n",
      "Current (running) training loss at iteration 15000 : 2.2775967017372447\n"
     ]
    }
   ],
   "source": [
    "training_df, val_df, test_df = split_dataset(ETTm2)\n",
    "\n",
    "#training\n",
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_features=len(training_df.columns), \n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = val_df, \n",
    "            target_column = ['OT'], \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size, \n",
    "            one_layer=one_layer\n",
    "            )\n",
    "\n",
    "test_data = DataLoader(TimeSeriesDataset(val_df,future_steps= future_steps, target_column = ['OT'],p_lag=p_lag), batch_size=batch_size,drop_last=True)\n",
    "plot_multistep_forecast(test_data=test_data, neural_net=net, future_steps=future_steps, number_of_forecasts=number_of_forecasts)\n",
    "evaluate_on_test_data(test_data = test_data, neural_net = net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETTm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, val_df, test_df = split_dataset(ETTm1)\n",
    "\n",
    "#training\n",
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_features=len(training_df.columns), \n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = val_df, \n",
    "            target_column = ['OT'], \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "test_data = DataLoader(TimeSeriesDataset(val_df,future_steps= future_steps, target_column = ['OT'],p_lag=p_lag), batch_size=batch_size,drop_last=True)\n",
    "plot_multistep_forecast(test_data=test_data, neural_net=net, future_steps=future_steps)\n",
    "evaluate_on_test_data(test_data = test_data, neural_net = net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETTh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, val_df, test_df = split_dataset(ETTh1)\n",
    "\n",
    "#training\n",
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_features=len(training_df.columns), \n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = val_df, \n",
    "            target_column = ['OT'], \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "test_data = DataLoader(TimeSeriesDataset(val_df,future_steps= future_steps, target_column = ['OT'],p_lag=p_lag), batch_size=batch_size,drop_last=True)\n",
    "plot_multistep_forecast(test_data=test_data, neural_net=net, future_steps=future_steps)\n",
    "evaluate_on_test_data(test_data = test_data, neural_net = net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETTh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#different datasets\n",
    "training_df, val_df, test_df = split_dataset(ETTh2)\n",
    "\n",
    "#training\n",
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_features=len(training_df.columns), \n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = val_df, \n",
    "            target_column = ['OT'], \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size\n",
    "            )\n",
    "\n",
    "test_data = DataLoader(TimeSeriesDataset(val_df,future_steps= future_steps, target_column = ['OT'],p_lag=p_lag), batch_size=batch_size,drop_last=True)\n",
    "plot_multistep_forecast(test_data=test_data, neural_net=net, future_steps=future_steps)\n",
    "evaluate_on_test_data(test_data = test_data, neural_net = net)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
