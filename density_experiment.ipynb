{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As of 6.6.24 this is not curated and some adjustments need to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import split_dataset, TimeSeriesDataset\n",
    "from utils.evaluation_utils import plot_multistep_forecast, evaluate_on_test_data\n",
    "from utils.training_utils import train\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "ETTm2 = pd.read_csv(\"/workspaces/time_series_experiment/ETT-small/ETTm2.csv\")\n",
    "training_df, val_df, test_df = split_dataset(ETTm2, remain_same = False)\n",
    "\n",
    "p_lag = 96\n",
    "future_steps = round(1)\n",
    "batch_size = 8\n",
    "epochs = 5\n",
    "learning_rate=1.e-4\n",
    "decomp_kernel_size = 24\n",
    "number_of_forecasts = 100\n",
    "target_column = ['OT']\n",
    "feature_columns = ['OT'] #[i for i in training_df.columns]\n",
    "modelling_task = 'univariate'\n",
    "\n",
    "net = train(\n",
    "            epochs = epochs, \n",
    "            n_continous_features=1, \n",
    "            n_categorial_features=0,\n",
    "            p_lag=  p_lag, \n",
    "            future_steps = future_steps, \n",
    "            training_df = training_df, \n",
    "            validation_df = val_df, \n",
    "            feature_columns = feature_columns,\n",
    "            target_column = target_column, \n",
    "            learning_rate=learning_rate ,\n",
    "            decomp_kernel_size= decomp_kernel_size, \n",
    "            batch_size=batch_size, \n",
    "            model = 'dlinear', \n",
    "            modelling_task = modelling_task, \n",
    "            density=True\n",
    "            )\n",
    "\n",
    "steps = 1000\n",
    "batch_size = 8\n",
    "p_lag = 96\n",
    "\n",
    "test_data = DataLoader(TimeSeriesDataset(test_df,future_steps= future_steps, target_column = target_column,feature_columns=feature_columns,p_lag=p_lag, modelling_task='univariate'), batch_size=batch_size,drop_last=True)      \n",
    "\n",
    "target_l = []\n",
    "for i, (inputs, targets) in enumerate(test_data): \n",
    "    if i > round(steps/batch_size): \n",
    "        break\n",
    "    else: \n",
    "        [target_l.append(i.item()) for i in targets.reshape(batch_size)]\n",
    "target_l = target_l[0:steps]\n",
    "\n",
    "output_l = []\n",
    "for i in range(steps): \n",
    "    if i == 0: \n",
    "        dist = net(inputs.squeeze(1))         \n",
    "        sample = dist.sample()\n",
    "        new_input = torch.cat((inputs[:,:,1:p_lag], sample.reshape(batch_size,1,1)),2)\n",
    "        [output_l.append([i.item()]) for i in sample.reshape(batch_size)]\n",
    "    else: \n",
    "        dist = net(new_input.squeeze(1))         \n",
    "        sample = dist.sample()\n",
    "        new_input = torch.cat((inputs[:,:,1:p_lag], sample.reshape(batch_size,1,1)),2)\n",
    "        for u in range(batch_size): \n",
    "            item = sample.reshape(batch_size)[u].item()\n",
    "            output_l[u].append(item)\n",
    "\n",
    "plt.plot(range(0, len(target_l)), target_l, 'g', label='target time series', alpha=1)\n",
    "for output in output_l: \n",
    "    plt.plot(range(0, len(target_l)), output, color='#F39C12',linewidth=1, linestyle='-.',alpha=0.4, label='pred time series' + \"\\n\" + f'{steps} steps')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
